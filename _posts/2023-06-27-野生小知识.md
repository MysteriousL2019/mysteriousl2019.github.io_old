---
title: Pytorch Tricks
author: Fangzheng
date: 2023-06-27 9:16:00 +0800
categories: [machine learning]
tags: [hint]
# pin: true
mermaid: true  #code模块
# comments: true
math: true
# img_cdn: https://github.com/MysteriousL2019/mysteriousl2019.github.io/tree/master/assets/img/
---
## 为何将batch size设置为1？
* 通常的项目为了将GPU的算力充分利用，会将batch size设置为一个较大的值
* 在pytorch version中关于目标检测的训练脚本，将batch size设置为了1是因为： 不同尺寸的图片打成同一个batch送到网络之前必然要resize（比如padding）成同一个尺寸，为了避免resize带来的干预，所以让一个batch只有一个图片是最好的（前提是你是用的数据尺寸不同，如果相同的话，当然大点好，跑满）
## 训练需要热身？（warm-up）
* 在训练初期，lr*warm-up（非常小的值），之后lr升高后，再通过正常训练下降。
* 在训练刚开始的时候，训练参数是random的，可能离最终的目标参数差距过大，如果不设置warm-up可能会导致训练不稳定
* 初次提出是resnet，之后李沐也发表过类似的
## 为何保存的权重文件这么大？
* 预训练的参数比自己训练的保存小很多
* 因为仅仅保存了model的权重，没有保存optimizer, lr, epoch

## pytorch Tensor中通道排列顺序
* [batch, channel, height, width]
* 一批的图片个数，通道数，高，宽

## 利用BP进行车牌分类
* 输入的RGB图像进行灰度化-》二值化 -- 因为结果只关注形状，与颜色无关
* 进行（滑动窗口），本质计算白色色块占卷积区域的比例
* 将卷积结果变为行向量，输入神经网络
* 使用one-hot编码输出层编码 完成25维 -> 10维的变化

# sklearn.model_selection的train_test_split
* X_train, X_test = train_test_split(X,test_size=0.3)
* y_train, y_test = train_test_split(y, test_size=0.3)
* X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
* 第一种写法分别对X和y进行了train_test_split，并且使用相同的test_size参数。这意味着，X和y中对应的样本会被分到相同的数据集中，但是它们的顺序可能不同，因为train_test_split函数默认会对数据进行随机打乱。因此，在第一种写法中，需要在后面手动将X_train和y_train以及X_test和y_test进行组合，保证它们的顺序一致。
* 而第二种写法直接对X和y同时进行train_test_split，并将结果赋值给四个变量。这样可以保证X_train与其对应的标签y_train，以及X_test与其对应的标签y_test是一一对应的，它们的顺序也是相同的。因此，第二种写法更加简洁易懂，推荐使用。
